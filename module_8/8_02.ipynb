{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2 Web Scraping I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Web-Scrapping es la forma que tenemos para referirnos a la captura de información de cualquier sitio web. Su objetivo es capturar información de forma automática.\n",
    "\n",
    "Las librerías principales que vamos a utilizar son beautifulsoup y requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso se divide principalmente en tres fases:\n",
    "\n",
    "- Carga de la dirección web a la que realizar el scrapping. A través de  requests.\n",
    "\n",
    "- Extracción del contenido de la web a partir de Beautifulsoup\n",
    "\n",
    "- Manipulación del contenido.\n",
    "\n",
    "- Para tablas podemos extraer directamente el contenido en pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de la URL\n",
    "\n",
    "Con requests podemos obtener el contenido de la pagina web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://es.wikipedia.org/wiki/El_lobo_de_Wall_Street'\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos preguntar si la conexion con esa pagina web ha funcionado. Es decir si la propiedad status_code que devuelve re es 200 o 201. Si es así, pasamos a la siguiente fase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En re.content tendremos todo el HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracción del contenido con Pandas\n",
    "\n",
    "Si usamos la función read_html sobre una URL. Nos data una lista de Dataframes con todas las tablas de la página.\n",
    "```python\n",
    "    dfs = pd.read_html(url)\n",
    "``` \n",
    "\n",
    "- Esta función nos da la opcion de filtrar con el parámetro match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_html('https://www.formula1.com/en/results.html/2023/drivers.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Extracción del contenido con BeautifulSoup\n",
    "\n",
    "Lo primero que tenemos que hacer es pasar al contenido que se encuentra en re.text a través de un parser de HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente que tenemos que hacer es identificar qué información es la que nos queremos descargar, y dónde se encuentra dentro del HTML\n",
    "\n",
    "Todos los elementos de una página tienen un xpath que es unívoco a ese elemento, por lo que puedes usarlo para recuperar la información\n",
    "\n",
    "- Inspeccionar, botón derecho sobre el elemento, copiar, copiar XPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./imgs/xpath.png\"  alt=\"drawing\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada uno de los resultados tienen la etiqueta li, y la clase list-resultado. Por lo que localizamos todos los elementos que cumplan estas condiciones y los guardamos\n",
    "\n",
    "<center>\n",
    "<img src=\"./imgs/ejemplo_1.png\"  alt=\"drawing\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturamos la ficha técnica de la película (la tabla que está a la derecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_a_extraer = soup.find_all('table',{'class' : 'infobox plainlist plainlinks'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(datos_a_extraer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(datos_a_extraer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_html = datos_a_extraer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablas = pd.read_html(str(tabla_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Manipulación del contenido\n",
    "\n",
    "En esta fase vamos iterando sobre lo que hemos conseguido con BeautifulSoup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es la primera tabla, por lo que debemos indicar que nos quedamos con únicamente esa tabla\n",
    "\n",
    "Las filas de la tabla tienen la etiqueta tr, por lo que localizamos todos los elementos que tengan dicha etiqueta, para iterar sobre ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_a_extraer = datos_a_extraer[0]\n",
    "trs = datos_a_extraer.find_all('tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al iterar sobre las filas, queremos extraer los elementos de las columnas de la izquierda th y de la derecha td\n",
    "\n",
    "Extraemos todos e iteramos sobre ellos para extraer la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_th = []\n",
    "rows_td = []\n",
    "\n",
    "for tr in trs:\n",
    "    \n",
    "    ths = tr.find_all('th')\n",
    "    tds = tr.find_all('td')\n",
    "    \n",
    "    for th in ths:\n",
    "                        \n",
    "        texto = th.text\n",
    "        # print(th.text)\n",
    "        rows_th.append(texto)\n",
    "        \n",
    "    for td in tds:\n",
    "                \n",
    "        texto = td.text\n",
    "        #print(td.text)\n",
    "        rows_td.append(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.DataFrame(np.column_stack([rows_th, rows_td]))\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, si analizamos el resultado obtenido, no es exáctamente lo que queremos.\n",
    "\n",
    "La información está descolocada. Y eso es porque hay varios elementos en la tabla que solo están en una de las dos columnas.\n",
    "\n",
    "Tenemos que identificarlos, y evitar descargarlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./imgs/tabla_mal.png\"  alt=\"drawing\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows_th = []\n",
    "rows_td = []\n",
    "\n",
    "for tr in trs:\n",
    "    \n",
    "    ths = tr.find_all('th')\n",
    "    tds = tr.find_all('td')\n",
    "    \n",
    "    for th in ths:\n",
    "        \n",
    "        if \"Ficha técnica\" in str(th) or \"Datos y cifras\" in str(th) or \"Compañías\" in str(th):\n",
    "            continue\n",
    "        \n",
    "        texto = th.text\n",
    "        # print(th.text)\n",
    "        rows_th.append(texto)\n",
    "        \n",
    "    for td in tds:\n",
    "        \n",
    "        if \"Ver todos los créditos\" in str(td) or \"Ficha\" in str(td) or \"Wikidata\" in str(td):\n",
    "            continue\n",
    "        \n",
    "        texto = td.text\n",
    "        texto = texto.replace('\\n',\"\")\n",
    "        #print(td.text)\n",
    "        rows_td.append(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.DataFrame(np.column_stack([rows_th, rows_td]))\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí que lo hemos conseguido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusión\n",
    "\n",
    "El proceso de Web-Scrapping no es un proceso complicado, pero si tedioso.\n",
    "Y es tedioso porque hay que comprender cuál es la estructura de la web que queremos scrappear y es posible que con el tiempo, un web-scrapper que funcionase, no nos funcione actualmente por qu hayan cambiado la estructura de la web.\n",
    "\n",
    "- Para asentar conocimientos, vamos a probar a extraer la misma información que ya obtuvimos haciendo este mismo proceso en R\n",
    "- Los primeros pasos son exáctamente iguales\n",
    "- Lo único que tenemos que adaptar es la url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2.1** De la página: https://www.expansion.com/mercados/cotizaciones/indices/ibex35_I.IB.html obten un daframe con los contenidos de la tabla de cotizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2.2** Extrae las noticias que aparecen el la web: https://www.expansion.com/mercados/cotizaciones/valores/telefonica_M.TEF.html, Generando un dataframe con la fecha, el título y el resumen de cada noticia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
